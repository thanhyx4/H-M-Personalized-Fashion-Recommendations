{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRC0DcygEQCIk92AFwZri7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhyx4/H-M-Personalized-Fashion-Recommendations/blob/main/Evaluate_top_K_Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "mmPOge2O5zpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precision @k"
      ],
      "metadata": {
        "id": "y_yy5xun6m_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(actual, predicted, k=10):\n",
        "  num_hits = 0\n",
        "    if len(predicted)>k:\n",
        "        predicted = predicted[:k]\n",
        "    for p in predicted:\n",
        "        if p in actual and p not in predicted[:k]:\n",
        "            num_hits += 1.0          \n",
        "    return num_hits/k\n"
      ],
      "metadata": {
        "id": "rsYHLbJWTjrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AP @K (Average Precision @K)"
      ],
      "metadata": {
        "id": "2sYmwsO9TCXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU6b4hCl5PHx"
      },
      "outputs": [],
      "source": [
        "def apk(actual, predicted, k=10):\n",
        "    \"\"\"\n",
        "    Computes the average precision at k.\n",
        "    This function computes the average prescision at k between two lists of\n",
        "    items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of elements that are to be predicted (order doesn't matter)\n",
        "    predicted : list\n",
        "                A list of predicted elements (order does matter)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    if len(predicted)>k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i,p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "    # remove this case in advance\n",
        "    # if not actual:\n",
        "    #     return 0.0\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recall @k"
      ],
      "metadata": {
        "id": "OCM3sU-a6twS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(actual, predicted, k=10):\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    num_hits = 0.0\n",
        "    actual_set = set(actual)\n",
        "\n",
        "    for p in predicted:\n",
        "        if p in actual_set:\n",
        "            num_hits += 1.0\n",
        "\n",
        "    return num_hits / len(actual)"
      ],
      "metadata": {
        "id": "QdnxMn35C_8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#F1 @k"
      ],
      "metadata": {
        "id": "Am9Jp0M5C-n5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_at_k(actual, predicted, k=10):\n",
        "    precision = precision_at_k(actual, predicted, k)\n",
        "    recall = recall_at_k(actual, predicted, k)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "xeP7VIVxDGNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAP @K (Mean Average Precision @K) "
      ],
      "metadata": {
        "id": "wj5xvkUCDGfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apk(actual, predicted, k=10):\n",
        "    \"\"\"\n",
        "    Computes the average precision at k.\n",
        "    This function computes the average prescision at k between two lists of\n",
        "    items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of elements that are to be predicted (order doesn't matter)\n",
        "    predicted : list\n",
        "                A list of predicted elements (order does matter)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    if len(predicted)>k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i,p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "    # remove this case in advance\n",
        "    # if not actual:\n",
        "    #     return 0.0\n",
        "\n",
        "    return score / min(len(actual), k)"
      ],
      "metadata": {
        "id": "Roi9pIQpTUXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def mapk(actual, predicted, k=10):\n",
        "    \"\"\"\n",
        "    Computes the mean average precision at k.\n",
        "    This function computes the mean average prescision at k between two lists\n",
        "    of lists of items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of lists of elements that are to be predicted \n",
        "             (order doesn't matter in the lists)\n",
        "    predicted : list\n",
        "                A list of lists of predicted elements\n",
        "                (order matters in the lists)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The mean average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
      ],
      "metadata": {
        "id": "b7HRqIl35wQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapk(\n",
        "    merged['valid_true'].map(lambda x: x.split()), \n",
        "    merged['valid_pred'].map(lambda x: x.split()), \n",
        "    k=12\n",
        ")"
      ],
      "metadata": {
        "id": "NCI6EtjJ6k45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mean Reciprocal Rank"
      ],
      "metadata": {
        "id": "plb5rg3TyDvw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rf9oGp6jDFiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nomalized Discounted Cumulative Gain"
      ],
      "metadata": {
        "id": "6L5LHxx8yHyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "true_relevance = np.asarray([[3,2,3,0,1,2]])\n",
        "#scores = np.asarray([[.1, .2, .3, 4, 70]])\n",
        "scores = np.asarray([[3,3,2,2,1,0]])\n",
        "ndcg_score(true_relevance, scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bd0qPr1yQ-j",
        "outputId": "e1d4b926-4b6a-434f-efcb-ee3d9d9b3f0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.920404822163683"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaCnF595ymun"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
